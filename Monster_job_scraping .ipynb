{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping of Job Posting from Monster website:\n",
    "Here we have tried to web scrap from Monster website for 2 locations USA and Canada with different job search keywords like Google cloud, AWS cloud, Azure Cloud, Google for education, G Suite(google workspace) and others.\n",
    "\n",
    "We have changed the input as text input for different searches and locations. We have also added URLs for navigation purposes (checking point).\n",
    "\n",
    "1. Programming Language used: Python\n",
    "2. Libraries used: Beautiful soup, requests, Pandas\n",
    "3. Jupyter Notebooks\n",
    "\n",
    "## Results:\n",
    "We have extracted 259 results for all the search keywords (Google cloud, AWS cloud and others) for USA and canada locations, saved in results_Monster.csv file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter job profile:  google cloud\n"
     ]
    }
   ],
   "source": [
    "#Importing liberaries for Web Scrapping of job posting on monster.\n",
    "from bs4 import BeautifulSoup as soup\n",
    "import requests\n",
    "import pandas as pd\n",
    "#Taking input from the user for job profile and location.\n",
    "x = input(\"Enter job profile: \").split(\" \")\n",
    "x = '-'.join(x)\n",
    "y = input(\"location: \")\n",
    "#searching the user input of monster\n",
    "URL = \"https://www.monster.com/jobs/search/?q=\"+x+\"&where=\"+y+\"&stpage=1&page=10\"\n",
    "page = requests.get(URL)\n",
    "#scr = soup(page.content, 'lxml')\n",
    "scr1 = soup(page.content, 'html.parser')\n",
    "print(URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scrapping for different information regarding each job such as profile, company name, location for job and links to apply on.\n",
    "# profile=[]\n",
    "#for header in scr.findAll('h2', {'class':'title'}):\n",
    "#    profile.append(header.text.strip())\n",
    "#company=[]\n",
    "#for name in scr.findAll('div', {'class':'company'}):\n",
    "#    company.append(name.text.strip())\n",
    "#links=[]\n",
    "#for link in scr.findAll('h2', {'class':'title'}):\n",
    "#    links.append(link.a['href'])\n",
    "#location=[]\n",
    "#for locs in scr.findAll('div', {'class':'location'}):\n",
    "#    location.append(locs.text.strip())\n",
    "#location = location[1:]\n",
    "\n",
    "profile1=[]\n",
    "for header in scr1.findAll('h2', {'class':'title'}):\n",
    "    profile1.append(header.text.strip())\n",
    "company1=[]\n",
    "for name in scr1.findAll('div', {'class':'company'}):\n",
    "    company1.append(name.text.strip())\n",
    "links1=[]\n",
    "for link in scr1.findAll('h2', {'class':'title'}):\n",
    "    links1.append(link.a['href'])\n",
    "location1=[]\n",
    "for locs in scr1.findAll('div', {'class':'location'}):\n",
    "    location1.append(locs.text.strip())\n",
    "location1 = location1[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Profile</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Location</th>\n",
       "      <th>Links</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist - Big Data, Google Cloud, Messy...</td>\n",
       "      <td>CyberCoders</td>\n",
       "      <td>Everett, WA</td>\n",
       "      <td>https://job-openings.monster.com/data-scientis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Software Developer( Java or Groovy/Google Cloud)</td>\n",
       "      <td>RK Management Consultants</td>\n",
       "      <td>Minneapolis, MN</td>\n",
       "      <td>https://job-openings.monster.com/software-deve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Google Cloud Platform - Cloud Engineer</td>\n",
       "      <td>Saicon Consultants Inc.</td>\n",
       "      <td>Trophy Club, TX</td>\n",
       "      <td>https://job-openings.monster.com/google-cloud-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Google Cloud Sys Engineer  (DevOps/SE)</td>\n",
       "      <td>Ciber Global</td>\n",
       "      <td>Orlando, FL</td>\n",
       "      <td>https://job-openings.monster.com/google-cloud-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Google Cloud Platform Architect</td>\n",
       "      <td>Cognizant</td>\n",
       "      <td>Phoenix, AZ</td>\n",
       "      <td>https://job-openings.monster.com/google-cloud-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>Sr. Manager, Software Engineer</td>\n",
       "      <td>Capital One</td>\n",
       "      <td>Clifton, VA</td>\n",
       "      <td>https://job-openings.monster.com/sr-manager-so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>Big Data Engineer</td>\n",
       "      <td>Cognizant</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>https://job-openings.monster.com/big-data-engi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>Senior Cloud Engineer</td>\n",
       "      <td>Jobot</td>\n",
       "      <td>Denver, CO</td>\n",
       "      <td>https://job-openings.monster.com/senior-cloud-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>Software Engineer, Java Applications</td>\n",
       "      <td>CyberCoders</td>\n",
       "      <td>San Mateo, CA</td>\n",
       "      <td>https://job-openings.monster.com/software-engi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>Sr. Product Marketing Manager</td>\n",
       "      <td>IBM</td>\n",
       "      <td>Raleigh, NC</td>\n",
       "      <td>https://job-openings.monster.com/sr-product-ma...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>260 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Profile  \\\n",
       "0    Data Scientist - Big Data, Google Cloud, Messy...   \n",
       "1     Software Developer( Java or Groovy/Google Cloud)   \n",
       "2               Google Cloud Platform - Cloud Engineer   \n",
       "3               Google Cloud Sys Engineer  (DevOps/SE)   \n",
       "4                      Google Cloud Platform Architect   \n",
       "..                                                 ...   \n",
       "255                     Sr. Manager, Software Engineer   \n",
       "256                                  Big Data Engineer   \n",
       "257                              Senior Cloud Engineer   \n",
       "258               Software Engineer, Java Applications   \n",
       "259                      Sr. Product Marketing Manager   \n",
       "\n",
       "                  Company Name           Location  \\\n",
       "0                  CyberCoders        Everett, WA   \n",
       "1    RK Management Consultants    Minneapolis, MN   \n",
       "2      Saicon Consultants Inc.    Trophy Club, TX   \n",
       "3                 Ciber Global        Orlando, FL   \n",
       "4                    Cognizant        Phoenix, AZ   \n",
       "..                         ...                ...   \n",
       "255                Capital One        Clifton, VA   \n",
       "256                  Cognizant  San Francisco, CA   \n",
       "257                      Jobot         Denver, CO   \n",
       "258                CyberCoders      San Mateo, CA   \n",
       "259                        IBM        Raleigh, NC   \n",
       "\n",
       "                                                 Links  \n",
       "0    https://job-openings.monster.com/data-scientis...  \n",
       "1    https://job-openings.monster.com/software-deve...  \n",
       "2    https://job-openings.monster.com/google-cloud-...  \n",
       "3    https://job-openings.monster.com/google-cloud-...  \n",
       "4    https://job-openings.monster.com/google-cloud-...  \n",
       "..                                                 ...  \n",
       "255  https://job-openings.monster.com/sr-manager-so...  \n",
       "256  https://job-openings.monster.com/big-data-engi...  \n",
       "257  https://job-openings.monster.com/senior-cloud-...  \n",
       "258  https://job-openings.monster.com/software-engi...  \n",
       "259  https://job-openings.monster.com/sr-product-ma...  \n",
       "\n",
       "[260 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# making a dictionary of the scrapped data.\n",
    "#d1 = {'Profile': profile, 'Company Name': company, 'Location': location, 'Links': links}\n",
    "d2 = {'Profile': profile1,'Company Name': company1, 'Location': location1,'Links': links1 }\n",
    "\n",
    "# comverting Data into dataframe.\n",
    "#df = pd.DataFrame.from_dict(d1)\n",
    "df1 = pd.DataFrame.from_dict(d2)\n",
    "#Exporting scrapped data into CSV file\n",
    "#df.to_csv(r'demo\\jobs.csv', index = False)#'demo\\jobs is temporary saving location.'\n",
    "df1.to_csv(r'results_Monster.csv', index = False)#'demo\\jobs is temporary saving location.'\n",
    "\n",
    "#display Data.\n",
    "#df\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
